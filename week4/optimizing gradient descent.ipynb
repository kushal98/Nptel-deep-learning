{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "df = pd.read_csv('toys.csv')\n",
    "X = df['X']\n",
    "Y = df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(w,b,x):\n",
    "    return 1/(1+np.exp(-(w*x+b)))\n",
    "\n",
    "def error(w,b):\n",
    "    err = 0\n",
    "    i=0\n",
    "    for x,y in zip(X,Y):\n",
    "        fx = sigmoid(w,b,x)\n",
    "        err = err+0.5*(fx-y)**2\n",
    "    return err\n",
    "\n",
    "def grad_w(w,b,x,y):\n",
    "    fx = sigmoid(w,b,x)\n",
    "    return (fx-y)*fx*(1-fx)*x\n",
    "\n",
    "def grad_b(w,b,x,y):\n",
    "    fx = sigmoid(w,b,x)\n",
    "    return (fx-y)*fx*(1-fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_w,init_b=1,1\n",
    "max_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_gd():\n",
    "    w,b,eta = init_w,init_b,1.0\n",
    "    prev_v_w,prev_v_b,gamma = 0,0,0.9\n",
    "    for i in range(max_epochs):\n",
    "        dw,db=0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw = dw + grad_w(w,b,x,y)\n",
    "            db = db + grad_b(w,b,x,y)\n",
    "        \n",
    "        v_w = gamma*prev_v_w + eta*dw\n",
    "        v_b = gamma*prev_v_b + eta*db\n",
    "        w = w - v_w\n",
    "        b = b - v_b\n",
    "        prev_v_w = v_w\n",
    "        prev_v_b = v_b\n",
    "        err= error(w,b)\n",
    "    print(\"momentum_grad:\")\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAG():\n",
    "    w,b,eta = init_w,init_b,1.0\n",
    "    prev_v_w,prev_v_b,gamma = 0,0,0.9\n",
    "    for i in range(max_epochs):\n",
    "        dw,db=0,0\n",
    "        #partial updates\n",
    "        v_w = gamma*prev_v_w\n",
    "        v_b = gamma*prev_v_b\n",
    "        for x,y in zip(X,Y):\n",
    "            dw = dw + grad_w(w-v_w,b-v_b,x,y)\n",
    "            db = db + grad_b(w-v_w,b-v_b,x,y)\n",
    "        \n",
    "        v_w = gamma*prev_v_w + eta*dw\n",
    "        v_b = gamma*prev_v_b + eta*db\n",
    "        w = w - v_w\n",
    "        b = b - v_b\n",
    "        prev_v_w = v_w\n",
    "        prev_v_b = v_b\n",
    "        err= error(w,b)\n",
    "    print(\"NAG:\")\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_gd():\n",
    "    w,b,eta = -2,-2,1.0\n",
    "    mini_batch_size,num_points_seen = 2,0\n",
    "    for i in range(max_epochs):\n",
    "        dw,db,num_points = 0,0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw = dw + grad_w(w,b,x,y)\n",
    "            db = db + grad_b(w,b,x,y)\n",
    "            num_points_seen += 1\n",
    "            \n",
    "            if num_points_seen % mini_batch_size == 0:\n",
    "                w = w - eta*dw\n",
    "                b = b - eta*db\n",
    "                dw,db= 0 , 0\n",
    "                \n",
    "        err= error(w,b)\n",
    "    print(\"Mini batch:\")\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gd():\n",
    "    w,b,eta = -2,-2,1.0\n",
    "    for i in range(max_epochs):\n",
    "        dw,db = 0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw = dw + grad_w(w,b,x,y)\n",
    "            db = db + grad_b(w,b,x,y)\n",
    "            w = w - eta*dw\n",
    "            b = b - eta*db\n",
    "        err= error(w,b)\n",
    "    print(\"stochastic grad:\")\n",
    "    print(err)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accl_momentum_gd():\n",
    "    w,b,eta = init_w,init_b,1.0\n",
    "    prev_v_w,prev_v_b,gamma = 0,0,0.9\n",
    "    for i in range(max_epochs):\n",
    "        dw,db=0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw = dw + grad_w(w,b,x,y)\n",
    "            db = db + grad_b(w,b,x,y)\n",
    "        \n",
    "            v_w = gamma*prev_v_w + eta*dw\n",
    "            v_b = gamma*prev_v_b + eta*db\n",
    "            w = w - v_w\n",
    "            b = b - v_b\n",
    "            prev_v_w = v_w\n",
    "            prev_v_b = v_b\n",
    "            err= error(w,b)\n",
    "    print(\"momentum accl:\")\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accl_NAG():\n",
    "    w,b,eta = init_w,init_b,1.0\n",
    "    prev_v_w,prev_v_b,gamma = 0,0,0.9\n",
    "    for i in range(max_epochs):\n",
    "        dw,db=0,0\n",
    "        #partial updates\n",
    "        v_w = gamma*prev_v_w\n",
    "        v_b = gamma*prev_v_b\n",
    "        for x,y in zip(X,Y):\n",
    "            dw = dw + grad_w(w-v_w,b-v_b,x,y)\n",
    "            db = db + grad_b(w-v_w,b-v_b,x,y)\n",
    "        \n",
    "            v_w = gamma*prev_v_w + eta*dw\n",
    "            v_b = gamma*prev_v_b + eta*db\n",
    "            w = w - v_w\n",
    "            b = b - v_b\n",
    "            prev_v_w = v_w\n",
    "            prev_v_b = v_b\n",
    "            err= error(w,b)\n",
    "    print(\"NAG accl:\")\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_serach():\n",
    "    w,b,etas = init_w ,init_b,[0.1,0.5,1.0,5.0,10.0]\n",
    "    for i in range(max_epochs):\n",
    "        dw,db=0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw += grad_w(w,b,x,y)\n",
    "            db += grad_b(w,b,x,y)\n",
    "        min_error = 10000   #set it to a large value\n",
    "        best_w,best_b = w,b\n",
    "        for eta in etas:\n",
    "            tmp_w = w - eta*dw\n",
    "            tmp_b = b - eta*db\n",
    "            if error(tmp_w,tmp_b) < min_error:\n",
    "                best_w = tmp_w\n",
    "                best_b = tmp_b\n",
    "                min_error = error(tmp_w,tmp_b)\n",
    "        w,b = best_w,best_b\n",
    "        err= error(w,b)\n",
    "    print(\"line search:\")\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adagrad():\n",
    "    w,b,eta = init_w,init_b,0.1\n",
    "    v_w,v_b,eps = 0,0,1e-8\n",
    "    for i in range(max_epochs):\n",
    "        dw,db=0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw += grad_w(w,b,x,y)\n",
    "            db += grad_b(w,b,x,y)\n",
    "            \n",
    "        v_w = v_w + dw**2\n",
    "        v_b = v_b +dw**2\n",
    "        \n",
    "        w = w - (eta/np.sqrt(v_w + eps))*dw\n",
    "        b = b - (eta/np.sqrt(v_b + eps))*db\n",
    "        err= error(w,b)\n",
    "    print(\"adagrad:\")\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsprop():\n",
    "    w,b,eta = init_w,init_b,0.1\n",
    "    v_w,v_b,eps,beta1= 0,0,1e-8,0.9\n",
    "    for i in range(max_epochs):\n",
    "        dw,db=0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw += grad_w(w,b,x,y)\n",
    "            db += grad_b(w,b,x,y)\n",
    "        \n",
    "        v_w = beta1 * v_w + (1 - beta1)*dw**2\n",
    "        v_b = beta1 * v_b + (1 - beta1)*db**2\n",
    "        \n",
    "        w = w - (eta/np.sqrt(v_w+eps))*dw\n",
    "        b = b - (eta/np.sqrt(v_b+eps))*db\n",
    "        err= error(w,b)\n",
    "    print(\"rmsprop:\")\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_optimizer():\n",
    "    w_b_dw_db = [(1,1,0,0)]\n",
    "    w_history,b_history,error_history = [],[],[]\n",
    "    \n",
    "    w,b,eta,mini_batch_size, num_points_seen = 1,1,0.1,10,0\n",
    "    \n",
    "    m_w,m_b,v_w,vb,eps,beta1,beta2 = 0,0,0,0,1e-8,0.9,0.99\n",
    "    for i in range(100):\n",
    "        dw,db=0,0\n",
    "        for x,y in zip(X,Y):\n",
    "            dw += grad_w(w,b,x,y)\n",
    "            db += grad_b(w,b,x,y)\n",
    "            \n",
    "        m_w = beta1*m_w + (1-beta1)*dw\n",
    "        m_b = beta1*m_b + (1-beta1)*db\n",
    "        \n",
    "        v_w = beta2*v_w + (1-beta2)*(dw**2)\n",
    "        vb = beta2*vb + (1-beta2)*(db**2)\n",
    "        \n",
    "        m_w = m_w/(1 - math.pow(beta1,i+1))\n",
    "        m_b = m_b/(1 - math.pow(beta1,i+1))\n",
    "        \n",
    "        v_w = v_w/(1 - math.pow(beta2,i+1))\n",
    "        vb = vb/(1 - math.pow(beta2,i+1))\n",
    "        \n",
    "        w = w - (eta/np.sqrt(v_w + eps)) * m_w\n",
    "        b = b - (eta/np.sqrt(vb + eps)) * m_b\n",
    "        err= error(w,b)\n",
    "    print(\"adam:\")\n",
    "    print(err)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "momentum_grad:\n",
      "1.0913943873622581e-06\n",
      "NAG:\n",
      "5.608446067034885e-09\n",
      "stochastic grad:\n",
      "0.038356161578280236\n",
      "Mini batch:\n",
      "2.3654398384865547e-05\n",
      "momentum accl:\n",
      "0.3052414948646977\n",
      "NAG accl:\n",
      "0.30455821299329605\n",
      "adagrad:\n",
      "0.001016469025396052\n",
      "rmsprop:\n",
      "0.0004439252066547889\n",
      "adam:\n",
      "0.015886036334059547\n"
     ]
    }
   ],
   "source": [
    "momentum_gd()\n",
    "NAG()\n",
    "stochastic_gd()\n",
    "mini_batch_gd()\n",
    "accl_momentum_gd()\n",
    "accl_NAG()\n",
    "line_serach\n",
    "adagrad()\n",
    "rmsprop()\n",
    "adam_optimizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
